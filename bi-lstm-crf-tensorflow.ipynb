{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sequence Classification Problem\n",
    "\n",
    "We will define a simple sequence classification problem to explore bidirectional LSTMs.\n",
    "\n",
    "The problem is defined as a sequence of random values between 0 and 1. \n",
    "\n",
    "A binary label (0 or 1) is associated with each input. Initially, the output values are all 0. Once the cumulative sum of the input values in the sequence exceeds a threshold, then the output value flips from 0 to 1.\n",
    "\n",
    "A threshold of 1/4 the sequence length is used.\n",
    "\n",
    "For example, below is a sequence of 10 input timesteps (X):\n",
    "\n",
    "```python\n",
    "0.63144003 0.29414551 0.91587952 0.95189228 0.32195638 0.60742236 0.83895793 0.18023048 0.84762691 0.29165514\n",
    "```\n",
    "\n",
    "In this case the threshold is `2.5` and the corresponding classification output (y) would be:\n",
    "\n",
    "```python\n",
    "0 0 0 1 1 1 1 1 1 1\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random as rand\n",
    "from random import random\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create a sequence classification instance\n",
    "def get_sequence(sequence_length):\n",
    "    # create a sequence of random numbers in [0,1]\n",
    "    X = np.array([random() for _ in range(sequence_length)])\n",
    "    # calculate cut-off value to change class values\n",
    "    limit = sequence_length / 4.0\n",
    "    # determine the class outcome for each item in cumulative sequence\n",
    "    y = array([0 if x < limit else 1 for x in np.cumsum(X)])\n",
    "    # reshape input and output data to be suitable for LSTMs\n",
    "#     X = X.reshape(1, sequence_length, 1)\n",
    "#     y = y.reshape(1, sequence_length, 1)\n",
    "    \n",
    "    return X, y\n",
    "\n",
    "# create n examples with random sequence lengths between 5 and 15\n",
    "def get_examples(n):\n",
    "    X_list = []\n",
    "    y_list = []\n",
    "    sequence_length_list = []\n",
    "    for _ in range(n):\n",
    "        sequence_length = rand.randrange(start=5, stop=15)\n",
    "        X, y = get_sequence(sequence_length)\n",
    "        X_list.append(X)\n",
    "        y_list.append(y)\n",
    "        sequence_length_list.append(sequence_length)\n",
    "    \n",
    "    return X_list, y_list, sequence_length_list\n",
    "\n",
    "# Tensorflow LSTM requires that all sentences inside the same batch have the same length\n",
    "# so we have to pad the data inside the batches with 0's\n",
    "def pad(sentence, max_length):\n",
    "    pad_len = max_length - len(sentence)\n",
    "    padding = np.zeros(pad_len)\n",
    "    return np.concatenate((sentence, padding))\n",
    "    \n",
    "# create batches\n",
    "def batch(data, labels, sequence_lengths, batch_size=2):\n",
    "    n_batch = int(math.ceil(len(data) / batch_size))\n",
    "    index = 0\n",
    "    for _ in range(n_batch):\n",
    "        batch_length = max(sequence_lengths[index: index + batch_size]) # max length in batch\n",
    "        batch_data = [pad(x, batch_length) for x in data[index: index + batch_size]] # pad data\n",
    "        batch_labels = labels[index: index + batch_size]\n",
    "        index += batch_size\n",
    "        yield batch_data, batch_labels, batch_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.53130889  0.67628029  0.21410701  0.01422941  0.78225318  0.10234613\n",
      "  0.78781767  0.12081531  0.86481415  0.02018286  0.64500628  0.80228549\n",
      "  0.61709186]\n",
      "[0 0 0 0 0 0 0 0 1 1 1 1 1]\n",
      "13\n",
      "[array([ 0.53130889,  0.67628029,  0.21410701,  0.01422941,  0.78225318,\n",
      "        0.10234613,  0.78781767,  0.12081531,  0.86481415,  0.02018286,\n",
      "        0.64500628,  0.80228549,  0.61709186]), array([ 0.33655061,  0.60009209,  0.87334623,  0.79084226,  0.71446592,\n",
      "        0.7129301 ,  0.46258968,  0.76642842,  0.69819853,  0.78910716,\n",
      "        0.77153211,  0.6652673 ,  0.74776988])]\n",
      "[array([0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1]), array([0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1])]\n",
      "13\n"
     ]
    }
   ],
   "source": [
    "x_train, y_train, sequence_length_train = get_examples(100)\n",
    "x_test, y_test, sequence_length_test = get_examples(30)\n",
    "print(x_train[0])\n",
    "print(y_train[0])\n",
    "print(sequence_length_train[0])\n",
    "for d, l, le in batch(x_train, y_train, sequence_length_train):\n",
    "    print(d)\n",
    "    print(l)\n",
    "    print(le)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/39808336/tensorflow-bidirectional-dynamic-rnn-none-values-error\n",
    "# https://www.tensorflow.org/api_docs/python/tf/nn/bidirectional_dynamic_rnn\n",
    "# https://guillaumegenthial.github.io/sequence-tagging-with-tensorflow.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# bidirectional lstm + CRF\n",
    "learning_rate   = 0.001\n",
    "training_epochs = 100\n",
    "input_size = 1\n",
    "batch_size  = 32\n",
    "num_units = 128 # the number of units in the LSTM cell\n",
    "number_of_classes = 2 # one-hot encoding\n",
    "\n",
    "input_data   = tf.placeholder(tf.float32, [None, None, input_size], name=\"input_data\")\n",
    "labels = tf.placeholder(tf.int32, shape=[None, None], name=\"labels\") # shape = (batch, sentence)\n",
    "seq_len = tf.placeholder(tf.int32, [None])\n",
    "\n",
    "lstm_fw_cell = tf.nn.rnn_cell.LSTMCell(num_units, forget_bias=1.0, state_is_tuple=True)\n",
    "lstm_bw_cell = tf.nn.rnn_cell.LSTMCell(num_units, forget_bias=1.0, state_is_tuple=True)\n",
    "(output_fw, output_bw), states = tf.nn.bidirectional_dynamic_rnn(cell_fw=lstm_fw_cell, \n",
    "                                                  cell_bw=lstm_bw_cell, \n",
    "                                                  inputs=input_data,\n",
    "                                                  sequence_length=seq_len, \n",
    "                                                  dtype=tf.float32)\n",
    "\n",
    "# As we have Bi-LSTM, we have two output, which are not connected. So merge them\n",
    "outputs = tf.concat([output_fw, output_bw], axis=2)\n",
    "\n",
    "# fully connected layer\n",
    "W = tf.get_variable(name=\"W\", shape=[2 * num_units, number_of_classes],\n",
    "                dtype=tf.float32)\n",
    "\n",
    "b = tf.get_variable(name=\"b\", shape=[number_of_classes], dtype=tf.float32,\n",
    "                initializer=tf.zeros_initializer())\n",
    "\n",
    "outputs_flat = tf.reshape(outputs, [-1, 2 * num_units])\n",
    "pred = tf.matmul(outputs_flat, W) + b\n",
    "scores = tf.reshape(pred, [-1, seq_len, number_of_classes])\n",
    "\n",
    "# linear-CRF\n",
    "log_likelihood, transition_params = tf.contrib.crf.crf_log_likelihood(scores, labels, sequence_lengths)\n",
    "\n",
    "loss = tf.reduce_mean(-log_likelihood)\n",
    "\n",
    "# training\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "train_op = optimizer.minimize(loss)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
